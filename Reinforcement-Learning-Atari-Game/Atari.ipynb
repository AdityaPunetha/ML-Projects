{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyglet\n",
      "  Using cached pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: pyglet\n",
      "Successfully installed pyglet-1.5.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyglet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying adventure.bin from .\\ROMS\\ROMS\\Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\adventure.bin\n",
      "copying air_raid.bin from .\\ROMS\\ROMS\\Air Raid (Men-A-Vision) (PAL) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\air_raid.bin\n",
      "copying alien.bin from .\\ROMS\\ROMS\\Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\alien.bin\n",
      "copying amidar.bin from .\\ROMS\\ROMS\\Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\amidar.bin\n",
      "copying assault.bin from .\\ROMS\\ROMS\\Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\assault.bin\n",
      "copying asterix.bin from .\\ROMS\\ROMS\\Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\asterix.bin\n",
      "copying asteroids.bin from .\\ROMS\\ROMS\\Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\asteroids.bin\n",
      "copying atlantis.bin from .\\ROMS\\ROMS\\Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\atlantis.bin\n",
      "copying bank_heist.bin from .\\ROMS\\ROMS\\Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\bank_heist.bin\n",
      "copying battle_zone.bin from .\\ROMS\\ROMS\\Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\battle_zone.bin\n",
      "copying beam_rider.bin from .\\ROMS\\ROMS\\Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\beam_rider.bin\n",
      "copying berzerk.bin from .\\ROMS\\ROMS\\Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\berzerk.bin\n",
      "copying bowling.bin from .\\ROMS\\ROMS\\Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\bowling.bin\n",
      "copying boxing.bin from .\\ROMS\\ROMS\\Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\boxing.bin\n",
      "copying breakout.bin from .\\ROMS\\ROMS\\Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\breakout.bin\n",
      "copying carnival.bin from .\\ROMS\\ROMS\\Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\carnival.bin\n",
      "copying centipede.bin from .\\ROMS\\ROMS\\Centipede (1983) (Atari - GCC) (CX2676) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\centipede.bin\n",
      "copying chopper_command.bin from .\\ROMS\\ROMS\\Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\chopper_command.bin\n",
      "copying crazy_climber.bin from .\\ROMS\\ROMS\\Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\crazy_climber.bin\n",
      "copying defender.bin from .\\ROMS\\ROMS\\Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\defender.bin\n",
      "copying demon_attack.bin from .\\ROMS\\ROMS\\Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\demon_attack.bin\n",
      "copying donkey_kong.bin from .\\ROMS\\ROMS\\Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\donkey_kong.bin\n",
      "copying double_dunk.bin from .\\ROMS\\ROMS\\Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\double_dunk.bin\n",
      "copying elevator_action.bin from .\\ROMS\\ROMS\\Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\elevator_action.bin\n",
      "copying enduro.bin from .\\ROMS\\ROMS\\Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\enduro.bin\n",
      "copying fishing_derby.bin from .\\ROMS\\ROMS\\Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\fishing_derby.bin\n",
      "copying freeway.bin from .\\ROMS\\ROMS\\Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\freeway.bin\n",
      "copying frogger.bin from .\\ROMS\\ROMS\\Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\frogger.bin\n",
      "copying frostbite.bin from .\\ROMS\\ROMS\\Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\frostbite.bin\n",
      "copying galaxian.bin from .\\ROMS\\ROMS\\Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\galaxian.bin\n",
      "copying gopher.bin from .\\ROMS\\ROMS\\Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\gopher.bin\n",
      "copying gravitar.bin from .\\ROMS\\ROMS\\Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\gravitar.bin\n",
      "copying hero.bin from .\\ROMS\\ROMS\\H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\hero.bin\n",
      "copying ice_hockey.bin from .\\ROMS\\ROMS\\Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\ice_hockey.bin\n",
      "copying jamesbond.bin from .\\ROMS\\ROMS\\James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\jamesbond.bin\n",
      "copying journey_escape.bin from .\\ROMS\\ROMS\\Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\journey_escape.bin\n",
      "copying kaboom.bin from .\\ROMS\\ROMS\\Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\kaboom.bin\n",
      "copying kangaroo.bin from .\\ROMS\\ROMS\\Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\kangaroo.bin\n",
      "copying keystone_kapers.bin from .\\ROMS\\ROMS\\Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\keystone_kapers.bin\n",
      "copying king_kong.bin from .\\ROMS\\ROMS\\King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\king_kong.bin\n",
      "copying koolaid.bin from .\\ROMS\\ROMS\\Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\koolaid.bin\n",
      "copying krull.bin from .\\ROMS\\ROMS\\Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\krull.bin\n",
      "copying kung_fu_master.bin from .\\ROMS\\ROMS\\Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\kung_fu_master.bin\n",
      "copying laser_gates.bin from .\\ROMS\\ROMS\\Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\laser_gates.bin\n",
      "copying lost_luggage.bin from .\\ROMS\\ROMS\\Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\lost_luggage.bin\n",
      "copying montezuma_revenge.bin from .\\ROMS\\ROMS\\Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\montezuma_revenge.bin\n",
      "copying mr_do.bin from .\\ROMS\\ROMS\\Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\mr_do.bin\n",
      "copying ms_pacman.bin from .\\ROMS\\ROMS\\Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\ms_pacman.bin\n",
      "copying name_this_game.bin from .\\ROMS\\ROMS\\Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\name_this_game.bin\n",
      "copying pacman.bin from .\\ROMS\\ROMS\\Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\pacman.bin\n",
      "copying phoenix.bin from .\\ROMS\\ROMS\\Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\phoenix.bin\n",
      "copying video_pinball.bin from .\\ROMS\\ROMS\\Pinball (AKA Video Pinball) (Zellers).bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\video_pinball.bin\n",
      "copying pitfall.bin from .\\ROMS\\ROMS\\Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\pitfall.bin\n",
      "copying pooyan.bin from .\\ROMS\\ROMS\\Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\pooyan.bin\n",
      "copying private_eye.bin from .\\ROMS\\ROMS\\Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\atari_roms\\private_eye.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\import_roms.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\import_roms.py\", line 89, in main\n",
      "    import_roms(args.dirpath)\n",
      "  File \"C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\atari_py\\import_roms.py\", line 74, in import_roms\n",
      "    with open(filepath, \"rb\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '.\\\\ROMS\\\\ROMS\\\\Pursuit of the Pink Panther (Pink Panther - The Video Game, Adventures of the Pink Panther) (1983) (Probe 2000 - NAP, Roger Booth, Todd Marshall, Robin McDaniel, Jim Wickstead) (3152VC) (Prototype) ~.bin'\n"
     ]
    }
   ],
   "source": [
    "!python -m atari_py.import_roms .\\ROMS\\ROMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"Breakout-v0\"\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]], [[[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]], (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajeev\\anaconda3\\envs\\cudaProject\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Score: 1.0\n",
      "Episode: 2 Score: 0.0\n",
      "Episode: 3 Score: 4.0\n",
      "Episode: 4 Score: 3.0\n",
      "Episode: 5 Score: 2.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode: {episode} Score: {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Vectorise Environment and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env(\"Breakout-v0\", n_envs=4, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join(\"Training\", \"Logs\")\n",
    "model = A2C(\"CnnPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | 1.61     |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | -0.113   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0856  |\n",
      "|    value_loss         | 0.00849  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 290      |\n",
      "|    ep_rew_mean        | 1.65     |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.618    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.08     |\n",
      "|    value_loss         | 0.0698   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 290      |\n",
      "|    ep_rew_mean        | 1.68     |\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0.435    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.0418  |\n",
      "|    value_loss         | 0.0288   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 289      |\n",
      "|    ep_rew_mean        | 1.68     |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0.672    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.141    |\n",
      "|    value_loss         | 0.0401   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 294      |\n",
      "|    ep_rew_mean        | 1.81     |\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.778    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.101   |\n",
      "|    value_loss         | 0.0182   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 300      |\n",
      "|    ep_rew_mean        | 1.94     |\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.819    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.0969  |\n",
      "|    value_loss         | 0.066    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | 2.11     |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0.961    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.0267  |\n",
      "|    value_loss         | 0.00406  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | 2.07     |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.37    |\n",
      "|    explained_variance | -0.0532  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.25     |\n",
      "|    value_loss         | 0.208    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | 2.18     |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.308    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.0708   |\n",
      "|    value_loss         | 0.296    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 319      |\n",
      "|    ep_rew_mean        | 2.42     |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.798   |\n",
      "|    explained_variance | -0.0197  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.313   |\n",
      "|    value_loss         | 0.281    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 353      |\n",
      "|    ep_rew_mean        | 3.11     |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 382      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.929   |\n",
      "|    explained_variance | 0.765    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.0441  |\n",
      "|    value_loss         | 0.0158   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 368      |\n",
      "|    ep_rew_mean        | 3.47     |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 417      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.595   |\n",
      "|    explained_variance | 0.893    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.131    |\n",
      "|    value_loss         | 0.078    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 386      |\n",
      "|    ep_rew_mean        | 3.88     |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 450      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | 0.57     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.184   |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 415      |\n",
      "|    ep_rew_mean        | 4.51     |\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 481      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0881  |\n",
      "|    explained_variance | 0.564    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.00192  |\n",
      "|    value_loss         | 0.0939   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 421      |\n",
      "|    ep_rew_mean        | 4.67     |\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 509      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.597   |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.0729  |\n",
      "|    value_loss         | 0.075    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 424      |\n",
      "|    ep_rew_mean        | 4.69     |\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 537      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.53    |\n",
      "|    explained_variance | 0.903    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.0751   |\n",
      "|    value_loss         | 0.104    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 440      |\n",
      "|    ep_rew_mean        | 5.1      |\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 562      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.927   |\n",
      "|    explained_variance | 0.861    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.0627   |\n",
      "|    value_loss         | 0.053    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 442      |\n",
      "|    ep_rew_mean        | 5.14     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 586      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.648   |\n",
      "|    explained_variance | 0.945    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.146    |\n",
      "|    value_loss         | 0.0733   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 438      |\n",
      "|    ep_rew_mean        | 5.05     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 612      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 0.655    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.154   |\n",
      "|    value_loss         | 0.321    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 443      |\n",
      "|    ep_rew_mean        | 5.15     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 643      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.719   |\n",
      "|    explained_variance | 0.944    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.0696   |\n",
      "|    value_loss         | 0.0311   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 450      |\n",
      "|    ep_rew_mean        | 5.35     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 677      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.91     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0359  |\n",
      "|    value_loss         | 0.0587   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 445      |\n",
      "|    ep_rew_mean        | 5.2      |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 710      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.806   |\n",
      "|    explained_variance | 0.911    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.0582  |\n",
      "|    value_loss         | 0.0286   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 447      |\n",
      "|    ep_rew_mean        | 5.19     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 740      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.798   |\n",
      "|    explained_variance | 0.63     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.162    |\n",
      "|    value_loss         | 0.0938   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 435      |\n",
      "|    ep_rew_mean        | 5.01     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 770      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.528   |\n",
      "|    explained_variance | 0.773    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.00486  |\n",
      "|    value_loss         | 0.134    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 430      |\n",
      "|    ep_rew_mean        | 4.9      |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 798      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1       |\n",
      "|    explained_variance | 0.868    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.0401  |\n",
      "|    value_loss         | 0.136    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 448      |\n",
      "|    ep_rew_mean        | 5.26     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 825      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.475   |\n",
      "|    explained_variance | 0.928    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.0134   |\n",
      "|    value_loss         | 0.0508   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 441      |\n",
      "|    ep_rew_mean        | 5.2      |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 853      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.724   |\n",
      "|    explained_variance | 0.767    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.0155  |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 450      |\n",
      "|    ep_rew_mean        | 5.41     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 886      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.934   |\n",
      "|    explained_variance | 0.734    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.203   |\n",
      "|    value_loss         | 0.249    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 452      |\n",
      "|    ep_rew_mean        | 5.42     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 916      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.913   |\n",
      "|    explained_variance | 0.933    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.139   |\n",
      "|    value_loss         | 0.0714   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 463      |\n",
      "|    ep_rew_mean        | 5.61     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 950      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.718   |\n",
      "|    explained_variance | 0.841    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.0289  |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 459      |\n",
      "|    ep_rew_mean        | 5.55     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 980      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.814   |\n",
      "|    explained_variance | 0.936    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.0148  |\n",
      "|    value_loss         | 0.0574   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 453      |\n",
      "|    ep_rew_mean        | 5.38     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 1010     |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.873   |\n",
      "|    explained_variance | 0.965    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.0128  |\n",
      "|    value_loss         | 0.0334   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 462      |\n",
      "|    ep_rew_mean        | 5.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 1038     |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.653   |\n",
      "|    explained_variance | 0.98     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.0559   |\n",
      "|    value_loss         | 0.0282   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 468      |\n",
      "|    ep_rew_mean        | 5.68     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 1068     |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1       |\n",
      "|    explained_variance | 0.32     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.00508 |\n",
      "|    value_loss         | 0.126    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 453      |\n",
      "|    ep_rew_mean        | 5.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 1099     |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0.283    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.0205   |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 450      |\n",
      "|    ep_rew_mean        | 5.37     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 1128     |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.52    |\n",
      "|    explained_variance | 0.907    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.0453   |\n",
      "|    value_loss         | 0.034    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 454      |\n",
      "|    ep_rew_mean        | 5.42     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 1159     |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.801   |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.131   |\n",
      "|    value_loss         | 0.0479   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 454      |\n",
      "|    ep_rew_mean        | 5.4      |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 1187     |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.507   |\n",
      "|    explained_variance | 0.995    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.0234  |\n",
      "|    value_loss         | 0.0192   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 454      |\n",
      "|    ep_rew_mean        | 5.39     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 1220     |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.427   |\n",
      "|    explained_variance | 0.88     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.00379 |\n",
      "|    value_loss         | 0.051    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 454      |\n",
      "|    ep_rew_mean        | 5.4      |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 1254     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.478   |\n",
      "|    explained_variance | 0.951    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.051   |\n",
      "|    value_loss         | 0.051    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 464      |\n",
      "|    ep_rew_mean        | 5.51     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 1287     |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.482   |\n",
      "|    explained_variance | 0.969    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.0416  |\n",
      "|    value_loss         | 0.0364   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 467      |\n",
      "|    ep_rew_mean        | 5.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 1321     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.382   |\n",
      "|    explained_variance | 0.932    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.0379   |\n",
      "|    value_loss         | 0.0567   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 469      |\n",
      "|    ep_rew_mean        | 5.56     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 1356     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.506   |\n",
      "|    explained_variance | 0.908    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.0342  |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 483      |\n",
      "|    ep_rew_mean        | 5.77     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 1390     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.394   |\n",
      "|    explained_variance | 0.882    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.0182   |\n",
      "|    value_loss         | 0.0947   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 491      |\n",
      "|    ep_rew_mean        | 5.86     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 1423     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.505   |\n",
      "|    explained_variance | 0.918    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.0121   |\n",
      "|    value_loss         | 0.0585   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 502      |\n",
      "|    ep_rew_mean        | 6.07     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 1457     |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.286   |\n",
      "|    explained_variance | 0.77     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.096   |\n",
      "|    value_loss         | 0.171    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 494      |\n",
      "|    ep_rew_mean        | 6.02     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 1491     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.781   |\n",
      "|    explained_variance | 0.854    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    value_loss         | 0.0741   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 484      |\n",
      "|    ep_rew_mean        | 5.91     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 1525     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.227   |\n",
      "|    explained_variance | 0.806    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.00655  |\n",
      "|    value_loss         | 0.087    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 478      |\n",
      "|    ep_rew_mean        | 5.83     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 1559     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.488   |\n",
      "|    explained_variance | 0.939    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.11     |\n",
      "|    value_loss         | 0.154    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 480      |\n",
      "|    ep_rew_mean        | 5.89     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 1593     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.435   |\n",
      "|    explained_variance | 0.92     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.0211   |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x181202d8760>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_path = os.path.join(\"Training\", \"Saved Models\", \"A2C_Breakout_Model\")\n",
    "model.save(a2c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C.load(a2c_path, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env(\"Breakout-v0\", n_envs=1, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.2, 3.249615361854384)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "820d38e3516b6e5c2784772beba4f3d77c0ca5a57beccbcfd727188b63c2ae2e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cudaProject': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
